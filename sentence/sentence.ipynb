{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import jieba, nltk, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name C:\\Users\\vmice/.cache\\torch\\sentence_transformers\\uer_sbert-base-chinese-nli. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "# model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "model = SentenceTransformer('uer/sbert-base-chinese-nli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['我想要去加入一个经常旅游的团队，因为我喜欢旅游。',\n",
    "            '我们团队平时会偶尔去旅游的。',\n",
    "            '经常去旅游的团队我不喜欢去。']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 768)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: 我想要去加入一个经常旅游的团队，因为我喜欢旅游。\n",
      "Embedding: (768,)\n",
      "Sentence: 我们团队平时会偶尔去旅游的。\n",
      "Embedding: (768,)\n",
      "Sentence: 经常去旅游的团队我不喜欢去。\n",
      "Embedding: (768,)\n"
     ]
    }
   ],
   "source": [
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5753\n",
      "0.0974\n"
     ]
    }
   ],
   "source": [
    "sim = util.cos_sim(embeddings[0], embeddings[1])\n",
    "print(\"{0:.4f}\".format(sim.tolist()[0][0]))\n",
    "sim = util.cos_sim(embeddings[2], embeddings[1])\n",
    "print(\"{0:.4f}\".format(sim.tolist()[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hits = util.semantic_search(queries_embeddings, corpus_embeddings, top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_text = '【岗位职责】：1.一起头脑风暴，基于一个现有应用场景，讨论更多产品细节或技术功能，或基于我们已有的技术内容，开动脑筋，协助挖掘更多的发明点。（每天参加两小时头脑风暴或者培训会议）2.根据我们提供的技术框架，查更多资料，补充一些技术细节。3.审阅我们已经写好的专利内容，润色语言，并撰写发明创新idea。发明领域包括但不限于跟物联网、信息、软件、电学、机械、生活等相关的应用，包括人工智能、出行、文旅、教育、医疗、酒店、办公、社区、租赁、运动、餐饮等等。你可以挑选一个工作方向进行完成。如果你有学习能力，我们会对你进行专业培训，让你熟悉发明甚至拥有自己的发明专利。【任职要求】：1.喜欢创新，头脑活跃，喜欢交流，乐于表达自己。2.偏理工科专业，软件、物联网、智能、计算机方向优先，优秀者可放宽至本科生；文科生但是学习过跟发明或者专利代理相关的知识的也可以尝试。3.有物联网或算法或信息分析能力的同学佳，不需要会编程，会写相关领域技术或者思维活跃有创造力就可以。【福利待遇】：1.创新挖掘，根据是否挖掘到成果，每次两小时，60-260元，根据挖掘到的想法数量质量决定。2.每一篇你参与创意挖掘或者撰写的发明，你都有机会作为共同发明人进行发明专利的发表。3.实习三个月，可以提供实习证明。4.公司提供专业培训、创新辅助系统、创意框架和撰写模板。5.参与头脑风暴或者创新培训的同学可以线上或线下参与（推荐线下），每周至少参与两次，每次至少两小时。'\n",
    "hunter_text = '信息与计算科学专业，c,c++有一定的基础知识，能够使用python进行编程，在校学习过数据库原理，'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seg_words(text : str):\n",
    "    seg_list = jieba.lcut(text)\n",
    "    interpunctuations = [',', '.', ':', ';', '?', '(', ')', '[', ']', '&', '!', '*', '@', '#', '$', '%', \n",
    "                    '，', '。', '：', '；', '？', '（', '）', '【', '】', '！', '￥', ' ', '、', '-']\n",
    "    seg_list = [word for word in seg_list if word not in interpunctuations]\n",
    "    stops = set(nltk.corpus.stopwords.words(\"chinese\"))\n",
    "    seg_list = [word for word in seg_list if word not in stops]\n",
    "    return seg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_sentences = get_seg_words(job_text)\n",
    "hunter_sentences = get_seg_words(hunter_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_text = job_text.replace('。', '. ')\n",
    "# # res = nltk.tokenize.word_tokenize(job_text)\n",
    "# print(job_text)\n",
    "\n",
    "# sentence = nltk.sent_tokenize(job_text)\n",
    "# print(sentence)\n",
    "# # job_text = ''.join(re.findall(r'[\\u4e00-\\u9fa5]', job_text))\n",
    "\n",
    "# seg_list = jieba.lcut(job_text)\n",
    "# print(seg_list)\n",
    "\n",
    "# interpunctuations = [',', '.', ':', ';', '?', '(', ')', '[', ']', '&', '!', '*', '@', '#', '$', '%', \n",
    "#                     '，', '。', '：', '；', '？', '（', '）', '【', '】', '！', '￥', ' ']\n",
    "# seg_list = [word for word in seg_list if word not in interpunctuations]\n",
    "# print(seg_list)\n",
    "\n",
    "# stops = set(nltk.corpus.stopwords.words(\"chinese\"))\n",
    "# seg_list = [word for word in seg_list if word not in stops]\n",
    "# print(seg_list)\n",
    "# # text = nltk.Text(seg_list)\n",
    "\n",
    "# type_tag = nltk.pos_tag(seg_list)\n",
    "# print(type_tag)\n",
    "\n",
    "# cut_word = []\n",
    "# for word in seg_list:\n",
    "#     cut_word.append(nltk.stem.PorterStemmer().stem(word))\n",
    "# print(cut_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['岗位职责',\n",
       "  '1',\n",
       "  '头脑',\n",
       "  '风暴',\n",
       "  '基于',\n",
       "  '一个',\n",
       "  '现有',\n",
       "  '场景',\n",
       "  '讨论',\n",
       "  '更',\n",
       "  '产品',\n",
       "  '细节',\n",
       "  '技术',\n",
       "  '功能',\n",
       "  '基于',\n",
       "  '已有',\n",
       "  '技术',\n",
       "  '内容',\n",
       "  '开动脑筋',\n",
       "  '协助',\n",
       "  '挖掘',\n",
       "  '更',\n",
       "  '发明',\n",
       "  '点',\n",
       "  '参加',\n",
       "  '两',\n",
       "  '小时',\n",
       "  '头脑',\n",
       "  '风暴',\n",
       "  '培训',\n",
       "  '会议',\n",
       "  '2',\n",
       "  '提供',\n",
       "  '技术',\n",
       "  '框架',\n",
       "  '查',\n",
       "  '更',\n",
       "  '资料',\n",
       "  '补充',\n",
       "  '技术细节',\n",
       "  '3',\n",
       "  '审阅',\n",
       "  '写',\n",
       "  '好',\n",
       "  '专利',\n",
       "  '内容',\n",
       "  '润色',\n",
       "  '语言',\n",
       "  '撰写',\n",
       "  '发明',\n",
       "  '创新',\n",
       "  'idea',\n",
       "  '发明',\n",
       "  '领域',\n",
       "  '包括',\n",
       "  '不',\n",
       "  '限于',\n",
       "  '跟物',\n",
       "  '联网',\n",
       "  '信息',\n",
       "  '软件',\n",
       "  '电学',\n",
       "  '机械',\n",
       "  '生活',\n",
       "  '相关',\n",
       "  '包括',\n",
       "  '人工智能',\n",
       "  '出行',\n",
       "  '文旅',\n",
       "  '教育',\n",
       "  '医疗',\n",
       "  '酒店',\n",
       "  '办公',\n",
       "  '社区',\n",
       "  '租赁',\n",
       "  '运动',\n",
       "  '餐饮',\n",
       "  '挑选',\n",
       "  '一个',\n",
       "  '工作',\n",
       "  '方向',\n",
       "  '学习',\n",
       "  '能力',\n",
       "  '会',\n",
       "  '专业培训',\n",
       "  '熟悉',\n",
       "  '发明',\n",
       "  '拥有',\n",
       "  '发明专利',\n",
       "  '任职',\n",
       "  '1',\n",
       "  '喜欢',\n",
       "  '创新',\n",
       "  '头脑',\n",
       "  '活跃',\n",
       "  '喜欢',\n",
       "  '交流',\n",
       "  '乐于',\n",
       "  '表达',\n",
       "  '2',\n",
       "  '偏',\n",
       "  '理工科',\n",
       "  '专业',\n",
       "  '软件',\n",
       "  '物',\n",
       "  '联网',\n",
       "  '智能',\n",
       "  '计算机',\n",
       "  '方向',\n",
       "  '优先',\n",
       "  '优秀者',\n",
       "  '放宽',\n",
       "  '本科生',\n",
       "  '文科生',\n",
       "  '学习',\n",
       "  '发明',\n",
       "  '专利',\n",
       "  '代理',\n",
       "  '相关',\n",
       "  '知识',\n",
       "  '尝试',\n",
       "  '3',\n",
       "  '有物',\n",
       "  '联网',\n",
       "  '算法',\n",
       "  '信息',\n",
       "  '分析',\n",
       "  '能力',\n",
       "  '同学',\n",
       "  '佳',\n",
       "  '不',\n",
       "  '会',\n",
       "  '编程',\n",
       "  '会',\n",
       "  '写',\n",
       "  '相关',\n",
       "  '领域',\n",
       "  '技术',\n",
       "  '思维',\n",
       "  '活跃',\n",
       "  '有创造力',\n",
       "  '福利待遇',\n",
       "  '1',\n",
       "  '创新',\n",
       "  '挖掘',\n",
       "  '挖掘',\n",
       "  '成果',\n",
       "  '每次',\n",
       "  '两',\n",
       "  '小时',\n",
       "  '60',\n",
       "  '260',\n",
       "  '元',\n",
       "  '挖掘',\n",
       "  '想法',\n",
       "  '数量质量',\n",
       "  '2',\n",
       "  '一篇',\n",
       "  '参与',\n",
       "  '创意',\n",
       "  '挖掘',\n",
       "  '撰写',\n",
       "  '发明',\n",
       "  '都',\n",
       "  '机会',\n",
       "  '发明人',\n",
       "  '发明专利',\n",
       "  '发表',\n",
       "  '3',\n",
       "  '实习',\n",
       "  '三个',\n",
       "  '月',\n",
       "  '提供',\n",
       "  '实习',\n",
       "  '证明',\n",
       "  '4',\n",
       "  '公司',\n",
       "  '提供',\n",
       "  '专业培训',\n",
       "  '创新',\n",
       "  '辅助',\n",
       "  '系统',\n",
       "  '创意',\n",
       "  '框架',\n",
       "  '撰写',\n",
       "  '模板',\n",
       "  '5',\n",
       "  '参与',\n",
       "  '头脑',\n",
       "  '风暴',\n",
       "  '创新',\n",
       "  '培训',\n",
       "  '同学',\n",
       "  '线上',\n",
       "  '线下',\n",
       "  '参与',\n",
       "  '推荐',\n",
       "  '线下',\n",
       "  '每周',\n",
       "  '至少',\n",
       "  '参与',\n",
       "  '两次',\n",
       "  '每次',\n",
       "  '至少',\n",
       "  '两',\n",
       "  '小时'],\n",
       " ['信息',\n",
       "  '计算',\n",
       "  '科学',\n",
       "  '专业',\n",
       "  'c',\n",
       "  'c++',\n",
       "  '基础知识',\n",
       "  'python',\n",
       "  '编程',\n",
       "  '在校',\n",
       "  '学习',\n",
       "  '数据库',\n",
       "  '原理'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_sentences, hunter_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4324\n"
     ]
    }
   ],
   "source": [
    "sentences = [job_sentences, hunter_sentences]\n",
    "embeddings = model.encode(sentences)\n",
    "sim = util.cos_sim(embeddings[0], embeddings[1])\n",
    "print(\"{0:.4f}\".format(sim.tolist()[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5019\n"
     ]
    }
   ],
   "source": [
    "sentences = [job_text, hunter_text]\n",
    "embeddings = model.encode(sentences)\n",
    "sim = util.cos_sim(embeddings[0], embeddings[1])\n",
    "print(\"{0:.4f}\".format(sim.tolist()[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
